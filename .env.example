# =============================================================================
# POC Realtime Voice AI - Environment Configuration
# =============================================================================
# Copy this file to .env and adjust as needed

# -----------------------------------------------------------------------------
# HuggingFace Token (required for gated models)
# -----------------------------------------------------------------------------
HF_TOKEN=

# -----------------------------------------------------------------------------
# Service Ports
# -----------------------------------------------------------------------------
ORCHESTRATOR_PORT=7860

# -----------------------------------------------------------------------------
# STT Configuration (faster-whisper-server)
# -----------------------------------------------------------------------------
STT_MODEL=Systran/faster-whisper-large-v3
STT_DEVICE=cuda
STT_COMPUTE_TYPE=float16
STT_LANGUAGE=de

# -----------------------------------------------------------------------------
# LLM Configuration (vLLM)
# -----------------------------------------------------------------------------
LLM_MODEL=stelterlab/Qwen3-30B-A3B-Instruct-2507-AWQ
LLM_MAX_CONTEXT=32768
# GPU memory utilization for vLLM. The model uses ~15.6 GiB, the rest is for KV-cache.
# For max_context=32768, at least 3.0 GiB KV-cache is needed.
# - 0.85: May cause "KV cache memory too small" errors with large context
# - 0.90: Recommended for 24GB GPUs (RTX 4090) with full context length
# - 0.95: Maximum, leaves minimal headroom for GPU operations
LLM_GPU_MEMORY=0.90
VLLM_ATTENTION_BACKEND=FLASHINFER
# Maximum concurrent sequences (vLLM default: 256)
# Lower values reduce sampler warmup memory but limit concurrent requests
# Set to 64 to prevent CUDA OOM during vLLM sampler warmup on 24GB GPUs
LLM_MAX_NUM_SEQS=64

# -----------------------------------------------------------------------------
# TTS Configuration
# -----------------------------------------------------------------------------
# Provider: coqui (default) | chatterbox
TTS_PROVIDER=coqui
TTS_DEVICE=cuda
TTS_SAMPLE_RATE=24000
TTS_LANGUAGE=de  # de=German, en=English, es=Spanish, fr=French, etc.

# Coqui-specific (only used when TTS_PROVIDER=coqui)
TTS_COQUI_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
# Preset speaker name (used if no speaker_wav is set) Gitta Nikolina/Claribel Dervla
TTS_COQUI_SPEAKER=Gitta Nikolina
# Optional: Path to speaker WAV for voice cloning
TTS_COQUI_SPEAKER_WAV=

# Chatterbox-specific (only used when TTS_PROVIDER=chatterbox)
# Lower values (0.3) improve stability for German, default 0.5
# See: https://github.com/resemble-ai/chatterbox
TTS_EXAGGERATION=0.3
TTS_CFG_WEIGHT=0.3

# -----------------------------------------------------------------------------
# Embedding / RAG Configuration
# -----------------------------------------------------------------------------
EMBEDDING_MODEL=BAAI/bge-m3
RAG_TOP_K=4

# -----------------------------------------------------------------------------
# Pipeline Configuration
# -----------------------------------------------------------------------------
VAD_SILENCE_MS=800
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Transport Mode
# -----------------------------------------------------------------------------
# "daily" (default): Uses Daily.co for hosted WebRTC
#   - Works reliably with cloud deployments (vast.ai, etc.)
#   - No port forwarding or TURN configuration needed
#   - Requires DAILY_API_KEY
#
# "local": Uses SmallWebRTC for direct connections
#   - Best for local development or LAN usage
#   - Direct peer-to-peer connection (no relay)
#   - No external services required
#
# "twilio": Uses Twilio Media Streams for telephone calls
#   - Voice agent reachable via phone number
#   - Requires TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, TWILIO_PHONE_NUMBER
#   - Requires ngrok or public URL for webhook
#
TRANSPORT_MODE=daily

# -----------------------------------------------------------------------------
# Daily.co Configuration (only needed when TRANSPORT_MODE=daily)
# -----------------------------------------------------------------------------
# Get your API key from: https://dashboard.daily.co/developers
DAILY_API_KEY=
DAILY_BOT_NAME=Voice Assistant
DAILY_ROOM_EXPIRY_TIME=3600

# -----------------------------------------------------------------------------
# Twilio Configuration (only needed when TRANSPORT_MODE=twilio)
# -----------------------------------------------------------------------------
# Get credentials from: https://console.twilio.com
TWILIO_ACCOUNT_SID=
TWILIO_AUTH_TOKEN=
# Twilio phone number in E.164 format (e.g. +1234567890)
TWILIO_PHONE_NUMBER=
# ngrok auth token for tunnel (optional, for docker-compose --profile twilio)
NGROK_AUTHTOKEN=

# -----------------------------------------------------------------------------
# GPU Configuration (Multi-GPU Setup)
# -----------------------------------------------------------------------------
# GPU device IDs for each service (use nvidia-smi to find IDs)
# For vast.ai with 2x RTX 4090:
#   GPU 0: STT + TTS (shared, lower VRAM usage)
#   GPU 1: LLM (exclusive, high VRAM usage)
STT_GPU_ID=0
TTS_GPU_ID=0
LLM_GPU_ID=1

# =============================================================================
# POC Realtime Voice AI - Environment Configuration
# =============================================================================
# Copy this file to .env and adjust as needed

# -----------------------------------------------------------------------------
# HuggingFace Token (required for gated models)
# -----------------------------------------------------------------------------
HF_TOKEN=

# -----------------------------------------------------------------------------
# Service Ports
# -----------------------------------------------------------------------------
ORCHESTRATOR_PORT=7860

# -----------------------------------------------------------------------------
# STT Configuration (faster-whisper-server)
# -----------------------------------------------------------------------------
STT_MODEL=Systran/faster-distil-whisper-large-v3
STT_DEVICE=cuda
STT_COMPUTE_TYPE=float16
STT_LANGUAGE=de

# -----------------------------------------------------------------------------
# LLM Configuration (vLLM)
# -----------------------------------------------------------------------------
LLM_MODEL=stelterlab/Qwen3-30B-A3B-Instruct-2507-AWQ
LLM_MAX_CONTEXT=32768
LLM_GPU_MEMORY=0.85
VLLM_ATTENTION_BACKEND=FLASHINFER

# -----------------------------------------------------------------------------
# TTS Configuration
# -----------------------------------------------------------------------------
# Provider: chatterbox (default) | coqui
TTS_PROVIDER=chatterbox
TTS_DEVICE=cuda
TTS_SAMPLE_RATE=24000
TTS_LANGUAGE=de  # de=German, en=English, es=Spanish, fr=French, etc.

# Coqui-specific (only used when TTS_PROVIDER=coqui)
TTS_COQUI_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
TTS_COQUI_SPEAKER_WAV=  # Optional: Path to speaker WAV for voice cloning

# -----------------------------------------------------------------------------
# Embedding / RAG Configuration
# -----------------------------------------------------------------------------
EMBEDDING_MODEL=BAAI/bge-m3
RAG_TOP_K=4

# -----------------------------------------------------------------------------
# Pipeline Configuration
# -----------------------------------------------------------------------------
VAD_SILENCE_MS=800
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Transport Mode
# -----------------------------------------------------------------------------
# "daily" (default): Uses Daily.co for hosted WebRTC
#   - Works reliably with cloud deployments (vast.ai, etc.)
#   - No port forwarding or TURN configuration needed
#   - Requires DAILY_API_KEY
#
# "local": Uses SmallWebRTC for direct connections
#   - Best for local development or LAN usage
#   - Direct peer-to-peer connection (no relay)
#   - No external services required
#
TRANSPORT_MODE=daily

# -----------------------------------------------------------------------------
# Daily.co Configuration (only needed when TRANSPORT_MODE=daily)
# -----------------------------------------------------------------------------
# Get your API key from: https://dashboard.daily.co/developers
DAILY_API_KEY=
DAILY_BOT_NAME=Voice Assistant
DAILY_ROOM_EXPIRY_TIME=3600

# -----------------------------------------------------------------------------
# GPU Configuration (Multi-GPU Setup)
# -----------------------------------------------------------------------------
# GPU device IDs for each service (use nvidia-smi to find IDs)
# For vast.ai with 2x RTX 4090:
#   GPU 0: STT + TTS (shared, lower VRAM usage)
#   GPU 1: LLM (exclusive, high VRAM usage)
STT_GPU_ID=0
TTS_GPU_ID=0
LLM_GPU_ID=1

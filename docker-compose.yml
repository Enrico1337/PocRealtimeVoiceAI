networks:
  voice-net:
    driver: bridge

volumes:
  qdrant-data:
  hf-cache:

services:
  # =============================================================================
  # QDRANT - Vector Database for RAG
  # =============================================================================
  qdrant:
    image: qdrant/qdrant:v1.12.1
    container_name: poc-qdrant
    restart: unless-stopped
    networks:
      - voice-net
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "true"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    ports:
      - "6333:6333"

  # =============================================================================
  # STT - Speech-to-Text (faster-whisper-server)
  # =============================================================================
  stt:
    image: fedirz/faster-whisper-server:latest-cuda
    container_name: poc-stt
    restart: unless-stopped
    networks:
      - voice-net
    environment:
      - WHISPER__MODEL=${STT_MODEL:-Systran/faster-distil-whisper-large-v3}
      - WHISPER__DEVICE=${STT_DEVICE:-cuda}
      - WHISPER__COMPUTE_TYPE=${STT_COMPUTE_TYPE:-float16}
    volumes:
      - hf-cache:/root/.cache/huggingface
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/health').read()\""]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 120s
    ports:
      - "8001:8000"

  # =============================================================================
  # LLM - Language Model (vLLM OpenAI Server)
  # =============================================================================
  llm:
    image: vllm/vllm-openai:latest
    container_name: poc-llm
    restart: unless-stopped
    networks:
      - voice-net
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
      - VLLM_ATTENTION_BACKEND=${VLLM_ATTENTION_BACKEND:-FLASHINFER}
    volumes:
      - hf-cache:/root/.cache/huggingface
    command: >
      --model ${LLM_MODEL:-stelterlab/Qwen3-30B-A3B-Instruct-2507-AWQ}
      --max-model-len ${LLM_MAX_CONTEXT:-32768}
      --gpu-memory-utilization ${LLM_GPU_MEMORY:-0.85}
      --dtype auto
      --trust-remote-code
      --port 8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 300s
    ports:
      - "8002:8000"

  # =============================================================================
  # TTS - Text-to-Speech (Custom Chatterbox Service)
  # =============================================================================
  tts:
    build:
      context: ./tts
      dockerfile: Dockerfile
    container_name: poc-tts
    restart: unless-stopped
    networks:
      - voice-net
    environment:
      - TTS_DEVICE=${TTS_DEVICE:-cuda}
      - TTS_SAMPLE_RATE=${TTS_SAMPLE_RATE:-24000}
    volumes:
      - hf-cache:/root/.cache/huggingface
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 120s
    ports:
      - "8003:8000"

  # =============================================================================
  # COTURN - Self-hosted TURN Server for WebRTC
  # =============================================================================
  coturn:
    image: coturn/coturn:latest
    container_name: poc-coturn
    restart: unless-stopped
    network_mode: host
    command:
      - -n
      - --log-file=stdout
      - --listening-port=3478
      - --tls-listening-port=5349
      - --min-port=49152
      - --max-port=49200
      - --realm=poc-voice
      - --user=turnuser:turnpassword
      - --lt-cred-mech
      - --fingerprint
      - --no-cli
      - --no-multicast-peers
    healthcheck:
      test: ["CMD", "turnutils_stunclient", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # =============================================================================
  # ORCHESTRATOR - Main Voice Pipeline
  # =============================================================================
  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    container_name: poc-orchestrator
    restart: unless-stopped
    network_mode: host
    environment:
      # Service URLs (via exposed ports on localhost)
      - STT_BASE_URL=http://localhost:8001
      - LLM_BASE_URL=http://localhost:8002
      - TTS_BASE_URL=http://localhost:8003
      - QDRANT_HOST=localhost
      - QDRANT_PORT=6333
      # Model configs
      - STT_MODEL=${STT_MODEL:-Systran/faster-distil-whisper-large-v3}
      - STT_LANGUAGE=${STT_LANGUAGE:-de}
      - LLM_MODEL=${LLM_MODEL:-stelterlab/Qwen3-30B-A3B-Instruct-2507-AWQ}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-BAAI/bge-m3}
      # Pipeline config
      - VAD_SILENCE_MS=${VAD_SILENCE_MS:-800}
      - RAG_TOP_K=${RAG_TOP_K:-4}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # TURN server credentials (for external TURN like metered.ca)
      - TURN_USERNAME=${TURN_USERNAME:-}
      - TURN_CREDENTIAL=${TURN_CREDENTIAL:-}
    volumes:
      - ./kb:/app/kb:ro
      - hf-cache:/root/.cache/huggingface
    depends_on:
      qdrant:
        condition: service_healthy
      stt:
        condition: service_healthy
      llm:
        condition: service_healthy
      tts:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s

  # =============================================================================
  # TEST - Quick import validation (no GPU needed)
  # Usage: docker-compose run --rm test
  # =============================================================================
  test:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    container_name: poc-test
    command: ["python", "test_imports.py"]
    profiles: ["test"]

  # =============================================================================
  # TEST-COTURN - TURN server connectivity test
  # Usage: docker compose --profile test-coturn run --rm test-coturn
  # =============================================================================
  test-coturn:
    image: coturn/coturn:latest
    container_name: poc-test-coturn
    network_mode: host
    entrypoint: ["turnutils_uclient"]
    command: ["-u", "turnuser", "-w", "turnpassword", "-p", "3478", "localhost"]
    profiles: ["test-coturn"]
    depends_on:
      coturn:
        condition: service_healthy
